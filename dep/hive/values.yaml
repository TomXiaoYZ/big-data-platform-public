# Default values for hive-beta.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 2

autoscaling:
  enabled: false

image:
  repository: 837282828706.dkr.ecr.ap-northeast-1.amazonaws.com/big-data-platform/hive
  tag: latest
  pullPolicy: Always

service:
  port: 10000

mysql:
  endpoint: mysql
  database: hive
  port: 3306
  username: root
  password: root

conf:
  loglevel: INFO
  hiveSite:
    hive.zookeeper.quorum: localhost:2181
    hive.llap.zk.sm.connectionString: localhost:2181
    hive.execution.engine: tez
    fs.defaultFS: hdfs://0.0.0.0:9000
    hive.metastore.uris: thrift://0.0.0.0:9083
    javax.jdo.option.ConnectionURL: jdbc:mysql://localhost:3306/hive
    javax.jdo.option.ConnectionDriverName: com.mysql.jdbc.Driver
    javax.jdo.option.ConnectionUserName: root
    javax.jdo.option.ConnectionPassword: root
    hive.server2.allow.user.substitution: true
    hive.server2.enable.doAs: true
    hive.server2.thrift.port: 10000
    hive.server2.thrift.http.port: 10001
    hive.optimize.ppd.input.formats: com.amazonaws.emr.s3select.hive.S3SelectableTextInputFormat
    s3select.filter: false
    hive.server2.in.place.progress: false
    hive.llap.zk.registry.user: hadoop
    hive.security.metastore.authorization.manager: org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider
    hive.log.explain.output: true
    datanucleus.fixedDatastore: true
    mapred.reduce.tasks: -1
    mapred.max.split:.size: 256000000
    hive.mapjoin.hybridgrace.hashtable: false
    hive.merge.nway.joins: false
    hive.metastore.connect.retries: 15
    hive.optimize.joinreducededuplication: false
    hive.optimize.sort.dynamic.partition: true
    hive.server2.materializedviews.registry.impl: DUMMY
    hive.tez.auto.reducer.parallelism: true
    hive.vectorized.execution.mapjoin.minmax.enabled: true
    hive.vectorized.execution.mapjoin.native.fast.hashtable.enabled: true
    hive.optimize.dynamic.partition.hashjoin: true
    hive.compactor.initiator.on: true
#    hive.llap.daemon.service.hosts: @llap0
    hive.llap.execution.mode: only
    hive.optimize.metadataonly: true
    hive.tez.bucket.pruning: true
    hive.exec.mode.local.auto: true
    hive.exec.mode.local.auto.inputbytes.max: 50000000
    hive.query.reexecution.stats.persist.scope: hiveserver
    hive.server2.authentication.ldap.baseDN: dc=example,dc=org
    hive.optimize.reducededuplication: true
    hive.exec.copyfile.maxsize: 33554432
    hive.vectorized.execution.enabled: false
    hive.auto.convert.join.noconditionaltask: true
    hive.stats.fetch.column.stats: false
    hive.compactor.worker.threads: 1
    hive.async.log.enabled: false
    hive.blobstore.optimizations.enabled: false
    hive.fetch.task.conversion: minimal
    hive.server2.authentication: LDAP
    hive.compute.query.using.stats: false
    hive.merge.mapredfiles: false
    hive.auto.convert.join.noconditionaltask.size: 2550136832
    hive.server2.authentication.ldap.url: ldap://localhost:1389
    hive.tez.container.size: 8192
    hive.blobstore.use.output-committer: true
    hive.auto.convert.join: true
    hive.groupby.orderby.position.alias: true
    hive.merge.mapfiles: true
    hive.llap.auto.allow.uber: true
    hive.metastore.warehouse.dir: hdfs:///hive
  hadoopConfigMap:
  hadoopSite:
  coreSite:
    fs.defaultFS: hdfs://localhost:9000
    ha.zookeeper.quorum: localhost:2181
    hadoop.security.authentication: simple
    hadoop.security.auth_to_local:
      RULE:[1:$1@$0](.*@)s/@.*///L
      RULE:[2:$1@$0](.*@)s/@.*///L
      DEFAULT
    hadoop.security.token.service.use_ip: true
#    hadoop.proxyuser.hive.hosts: *
#    hadoop.proxyuser.hive.groups: *
#    hadoop.proxyuser.httpfs.hosts: *
#    hadoop.proxyuser.httpfs.groups: *
#    hadoop.proxyuser.hue.hosts: *
#    hadoop.proxyuser.hue.groups: *
#    hadoop.proxyuser.livy.hosts: *
#    hadoop.proxyuser.livy.groups: *
#    hadoop.proxyuser.oozie.hosts: *
#    hadoop.proxyuser.oozie.groups: *
#    hadoop.proxyuser.presto.hosts: *
#    hadoop.proxyuser.presto.groups: *
#    hadoop.proxyuser.trino.hosts: *
#    hadoop.proxyuser.trino.groups: *
#    hadoop.proxyuser.hadoop.groups: *
#    hadoop.proxyuser.hadoop.hosts: *
    io.compression.codecs: org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec
    io.compression.codec.lzo.class: com.hadoop.compression.lzo.LzoCodec
    fs.s3.buffer.dir: /mnt/s3,/mnt1/s3,/mnt2/s3,/mnt3/s3
    hadoop.security.credstore.java-keystore-provider.password-file: keystore.password
    ipc.client.connect.max.retries.on.timeouts: 5
    hadoop.security.key.default.bitlength: 256
    hadoop.http.filter.initializers: org.apache.hadoop.security.HttpCrossOriginFilterInitializer,org.apache.hadoop.yarn.server.security.http.RMAuthenticationFilterInitializer,org.apache.hadoop.http.lib.StaticUserWebFilter
    hadoop.tmp.dir: /mnt/var/lib/hadoop/tmp
    hadoop.security.group.mapping: org.apache.hadoop.security.LdapGroupsMapping
    hadoop.security.group.mapping.ldap.bind.user: cn=admin,dc=example,dc=org
    hadoop.security.group.mapping.ldap.bind.password: admin
    hadoop.security.group.mapping.ldap.url: ldap://localhost:1389
    fs.s3.impl: com.amazon.ws.emr.hadoop.fs.EmrFileSystem
    fs.s3n.impl: com.amazon.ws.emr.hadoop.fs.EmrFileSystem
    fs.AbstractFileSystem.s3.impl: org.apache.hadoop.fs.s3.EMRFSDelegate
    fs.s3bfs.impl: org.apache.hadoop.fs.s3.S3FileSystem
    fs.s3.buckets.create.region: ap-northeast-1
    io.file.buffer.size: 65336
  hdfsSite:
    dfs.datanode.use.datanode.hostname: false
    dfs.client.use.datanode.hostname: false
    dfs.datanode.hostname: example.com
    dfs.datanode.http.address: 0.0.0.0:9864
    dfs.datanode.address: 0.0.0.0:9866
    dfs.replication: 3
    dfs.datanode.data.dir: file:///root/hdfs/datanode
    dfs.namenode.name.dir: file:///root/hdfs/namenode
    dfs.namenode.datanode.registration.ip-hostname-check: false
    dfs.namenode.rpc-bind-host: 0.0.0.0
    dfs.namenode.servicerpc-bind-host: 0.0.0.0
  yarnSite:
    yarn.resourcemanager.resource-tracker.address: localhost:8025
    yarn.resourcemanager.address: localhost:8032
    yarn.resourcemanager.scheduler.address: localhost:8030
    yarn.resourcemanager.admin.address: localhost:8033
    yarn.resourcemanager.webapp.address: localhost:8088
    yarn.resourcemanager.hostname: localhost
    yarn.resourcemanager.bind-host: localhost
    yarn.resourcemanager.zk-address: localhost:2181
    yarn.nodemanager.aux-services: mapreduce_shuffle,
    yarn.nodemanager.aux-services.mapreduce_shuffle.class: org.apache.hadoop.mapred.ShuffleHandler
    yarn.log-aggregation-enable: true
    yarn.log.server.url: http://localhost:19888/jobhistory/logs
    hadoop.registry.zk.quorum: localhost:2181
    yarn.application.classpath:
      $HADOOP_CONF_DIR,
      $HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,
      $HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,
      $HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,
      $HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,
      /usr/lib/hadoop-lzo/lib/*,
      /usr/share/aws/emr/emrfs/conf,
      /usr/share/aws/emr/emrfs/lib/*,
      /usr/share/aws/emr/emrfs/auxlib/*,
      /usr/share/aws/emr/lib/*,
      /usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar,
      /usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar,
      /usr/share/aws/emr/kinesis/lib/emr-kinesis-hadoop.jar,
      /usr/share/aws/emr/cloudwatch-sink/lib/*,
      /usr/share/aws/aws-java-sdk/*
    yarn.nodemanager.hostname: localhost
    yarn.nodemanager.bind-host: localhost
    yarn.timeline-service.hostname: localhost
    yarn.timeline-service.bind-host: localhost
  mapredSite:
    mapreduce.framework.name: yarn
    mapreduce.jobhistory.address: localhost:10020
    mapreduce.jobhistory.webapp.address: localhost:19888

resources:
  requests:
    memory: "256Mi"
    cpu: "10m"
  limits:
    memory: "2048Mi"
    cpu: "1000m"

affinity: {}